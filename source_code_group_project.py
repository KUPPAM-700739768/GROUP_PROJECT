# -*- coding: utf-8 -*-
"""Source Code Group Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QzCCsZvyPegZFxvEcxbl_OAz-E1D9qml

**Importing Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
# import warnings
# warnings.filterwarnings("ignore")

df = pd.read_csv('data.csv')
df.head()

"""**DATA CLEANING**"""

df.describe().T

df.info()

"""<p>The Unnamed: 32 column is full of null values so it is not contributing to dataset we need to remove the column</p>"""

df = df.drop(['id', 'Unnamed: 32'], axis=1)
df.isnull().sum().sum()

df.dtypes

"""**VISUALIZING THE DATA**"""

df.corr()

plt.figure(figsize=(20,10))
sns.heatmap(df.corr(), annot= True, cmap='Accent')

sns.barplot(x=df.diagnosis.value_counts().index, y=df.diagnosis.value_counts())
plt.title('Benign vs malignant cancer', fontsize=15)
plt.show()

sns.barplot(x='radius_mean', y='texture_mean', data=df[100:110])
plt.title("Radius vs Texture mean of sample")

df.columns

# Pairplot for mean data columns
mean_columns = ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',
       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']
# sns.pairplot(df[mean_columns], hue='diagnosis', palette='Accent')

# worst_columns paitplot 
worst_col = ['diagnosis', 'radius_worst', 'texture_worst',
       'perimeter_worst', 'area_worst', 'smoothness_worst',
       'compactness_worst', 'concavity_worst', 'concave points_worst',
       'symmetry_worst', 'fractal_dimension_worst']
# sns.pairplot(df[worst_col], hue='diagnosis', palette='Accent_r')

"""**TRAINING AND TESTING DATASET**"""

X = df.drop('diagnosis',axis=1)
Y = df['diagnosis'].replace({'B': 1, 'M': 0})

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = pd.DataFrame(scaler.fit_transform(X))

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)



print("Count of Training samples: ", len(x_train) )
print("Count of Testing samples: ", len(x_test) )

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(x_train, y_train)

y_pred = model.predict(x_test)
pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
print("Classification Report: ", classification_report(y_test,y_pred))
print("Confusion matrix: \n", confusion_matrix(y_test, y_pred))
print("Training Score: ", model.score(x_train, y_train)*100)
print("Accuracy Score: ",accuracy_score(y_test, y_pred)*100)

"""**Decision Tree Algorithm**"""

from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(max_depth=6, random_state=10)
tree.fit(x_train, y_train)

y_pred = tree.predict(x_test)
pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

print("Classification Report for Decision Tree: ",classification_report(y_test, y_pred))
print("Confusion Matrix for Decision Tree Model: \n", confusion_matrix(y_test, y_pred))
print("Training Score for Decision Tree Model: ", tree.score(x_train, y_train)*100)
print("Accuracy Score of Decision Tree Model: ", accuracy_score(y_test, y_pred)*100)

"""**Support Vector Machines (SVM)**"""

from sklearn.svm import SVC
svc = SVC()
svc.fit(x_train, y_train)

y_pred = svc.predict(x_test)
print("Classification Report for SVC Model: ", classification_report(y_test, y_pred))
print("Confusion Matrix for SVC Model: \n", confusion_matrix(y_test, y_pred))
print("Training Score of SVC Model: ", svc.score(x_train, y_train)*100)
print("Accuracy Score of SVC Model is: ", accuracy_score(y_test, y_pred)*100)

"""**XGBoost Classifier**"""

from xgboost import XGBClassifier
xgb = XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)
xgb.fit(x_train, y_train)

y_pred = xgb.predict(x_test)
print("Classificaiton Report for XGBoost Model: ", classification_report(y_test, y_pred))
print("Confusion Matrix for XGBoost Model: \n",confusion_matrix(y_test, y_pred) )
print("Training Score of XGBoost Model: ", xgb.score(x_train, y_train)*100)
print("Accuracy Score of XGBoost Model: ", accuracy_score(y_test, y_pred)*100)

"""**KNearest Neighbours Algorithms**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=2)
knn.fit(x_train, y_train)

y_pred = knn.predict(x_test)

print("Classification Report for KNN: ", classification_report(y_test, y_pred))
print("Confusion Matrix for KNN model: \n", confusion_matrix(y_test, y_pred))
print("Training Accuracy of KNN Model is: ", knn.score(x_train, y_train)*100)
print("Accuracy score of knn Model: ", accuracy_score(y_test, y_pred)*100)

